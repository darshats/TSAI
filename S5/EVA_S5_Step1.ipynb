{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA- S5-Step1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMpjPVBxKl0f"
      },
      "source": [
        "This step puts basic skeleton in place. \n",
        "\n",
        "**Target**\n",
        "parameters less than 20k\n",
        "\n",
        "1.   Basic skeleton in place. Skip higher number of filters, digits do not have that many textures and patterns (circles, corners, angle lines) so max 24 filters. \n",
        "2.   Parameters less than 20k. Use 1x1 convs to keep #filters in check and trim\n",
        "filters that are not useful\n",
        "\n",
        "**Results**\n",
        "Shows potential\n",
        "\n",
        "1. Params 9058\n",
        "2. best train accuracy 99.48\n",
        "3. best test accuracy 99.01\n",
        "4. Shows overfitting, test accuracy is <=99. \n",
        "5. Not converging fast enough. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        ## INPUT BLOCK\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3), \n",
        "            nn.BatchNorm2d(num_features=8, eps=1e-05, momentum=0.1),\n",
        "            nn.ReLU()\n",
        "        ) #i 28 o 26 RF 3\n",
        "\n",
        "        ## BLOCK 1\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(8, 16, 3), \n",
        "            nn.BatchNorm2d(num_features=16, eps=1e-05, momentum=0.1),\n",
        "            nn.ReLU()\n",
        "        ) #i 26 o 24 RF 5\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(16, 24, 3), \n",
        "            nn.BatchNorm2d(num_features=24, eps=1e-05, momentum=0.1),\n",
        "            nn.ReLU()\n",
        "        ) #i 24 o 22\n",
        "\n",
        "        ## TRANSITION BLOCK\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) #i 22 o 11\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(24, 16, 1), \n",
        "            nn.BatchNorm2d(num_features=16, eps=1e-05, momentum=0.1),\n",
        "            nn.ReLU()\n",
        "        ) #i 11 o 11\n",
        "\n",
        "        \n",
        "        #self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "        ## BLOCK 2\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(16, 16, 3),\n",
        "            nn.BatchNorm2d(num_features=16, eps=1e-05, momentum=0.1),\n",
        "            nn.ReLU()\n",
        "        ) #i 11 o 9\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2, 2) #i 9 o 4\n",
        "\n",
        "        ## OUTPUT BLOCK\n",
        "        self.convblock6 = nn.Sequential(\n",
        "            nn.Conv2d(16, 10, 3), #i4 o 2\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )  \n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        ## block 1\n",
        "        x = self.convblock1(x) \n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.pool1(x) \n",
        "        x = self.convblock4(x) \n",
        "        x = self.convblock5(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.convblock6(x) \n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdydjYTZFyi3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa4e5c2-55c9-47a4-d3df-189c949f6324"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              80\n",
            "       BatchNorm2d-2            [-1, 8, 26, 26]              16\n",
            "              ReLU-3            [-1, 8, 26, 26]               0\n",
            "            Conv2d-4           [-1, 16, 24, 24]           1,168\n",
            "       BatchNorm2d-5           [-1, 16, 24, 24]              32\n",
            "              ReLU-6           [-1, 16, 24, 24]               0\n",
            "            Conv2d-7           [-1, 24, 22, 22]           3,480\n",
            "       BatchNorm2d-8           [-1, 24, 22, 22]              48\n",
            "              ReLU-9           [-1, 24, 22, 22]               0\n",
            "        MaxPool2d-10           [-1, 24, 11, 11]               0\n",
            "           Conv2d-11           [-1, 16, 11, 11]             400\n",
            "      BatchNorm2d-12           [-1, 16, 11, 11]              32\n",
            "             ReLU-13           [-1, 16, 11, 11]               0\n",
            "           Conv2d-14             [-1, 16, 9, 9]           2,320\n",
            "      BatchNorm2d-15             [-1, 16, 9, 9]              32\n",
            "             ReLU-16             [-1, 16, 9, 9]               0\n",
            "        MaxPool2d-17             [-1, 16, 4, 4]               0\n",
            "           Conv2d-18             [-1, 10, 2, 2]           1,450\n",
            "AdaptiveAvgPool2d-19             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 9,058\n",
            "Trainable params: 9,058\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.70\n",
            "Params size (MB): 0.03\n",
            "Estimated Total Size (MB): 0.74\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "\n",
        "\n",
        "torch.manual_seed(1)\n",
        "batch_size = 256\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    correct = 0\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "        ## accumulate correct over each batch\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    print(f'Epoch {epoch}, train accuracy {100*correct / len(train_loader.dataset)}')\n",
        "\n",
        "def test(model, device, test_loader, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print(f'Epoch {epoch}, test accuracy {100. * correct / len(test_loader.dataset)}')\n",
        "    # print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    #     test_loss, correct, len(test_loader.dataset),\n",
        "    #     100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMWbLWO6FuHb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f39ad3-d4cf-4045-db6b-3ad4ad08185b"
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "for epoch in range(1, 16):\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader, epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/235 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "loss=0.1534167379140854 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, train accuracy 89.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, test accuracy 96.09\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.1428501456975937 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, train accuracy 97.61166666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, test accuracy 98.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.051603201776742935 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, train accuracy 98.18166666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, test accuracy 98.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.03382066264748573 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, train accuracy 98.48333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, test accuracy 98.45\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.025210464373230934 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, train accuracy 98.68333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, test accuracy 98.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.044026169925928116 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, train accuracy 98.805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, test accuracy 98.51\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.04324883595108986 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, train accuracy 98.93833333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, test accuracy 98.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.0786801278591156 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, train accuracy 99.04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, test accuracy 98.83\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.01645025424659252 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, train accuracy 99.10166666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, test accuracy 98.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.022150347009301186 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, train accuracy 99.15333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, test accuracy 98.96\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.017302006483078003 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, train accuracy 99.24166666666666\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, test accuracy 98.86\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.01737177185714245 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, train accuracy 99.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, test accuracy 98.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.004603361710906029 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, train accuracy 99.36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, test accuracy 99.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.002201046561822295 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, train accuracy 99.41666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, test accuracy 98.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.025155993178486824 batch_id=234: 100%|██████████| 235/235 [00:19<00:00, 11.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, train accuracy 99.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, test accuracy 98.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
