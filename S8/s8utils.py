# -*- coding: utf-8 -*-
"""S8utils.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZASiP6m62FbAEGyXN5EfbxIhUZDbnZeH
"""

from __future__ import print_function
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torchvision import datasets, transforms
import torchvision.transforms.functional as FF
import albumentations as A
from albumentations.augmentations.transforms import Cutout, Normalize
from albumentations.pytorch.transforms import ToTensorV2
from cifardataset import Cifar10SearchDataset
from gradcam import compute_gradcam_image

def create_train_test_sets(mean, std):
    train_transform = A.Compose([Normalize(mean=(mean,mean,mean), std=(std,std,std)),
                                A.RandomCrop(32,32),
                                A.Cutout(num_holes=1, max_h_size=16, max_w_size=16),
                                ToTensorV2()
                                ])
    
    trainset = Cifar10SearchDataset(root="~/data/cifar10", 
                                    train=True, 
                                    download=True, 
                                    transform=train_transform
                                   )
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=512,
                                            shuffle=True, num_workers=2)
    
    
    test_transform = A.Compose([Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),
                                        ToTensorV2()])
    testset = Cifar10SearchDataset(root='./data', 
                                   train=False,
                                   download=True, 
                                   transform=test_transform)
    testloader = torch.utils.data.DataLoader(testset, batch_size=512,
                                          shuffle=False, num_workers=2)

    return trainloader, testloader


def show_internal(imgs):
    if not isinstance(imgs, list):
        imgs = [imgs]
    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)
    for i, img in enumerate(imgs):
        img = img.detach()
        img = FF.to_pil_image(img)
        axs[0, i].imshow(np.asarray(img))
        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])
        
        
def show(incorrect_images, STD, MEAN):
    normalized_images = []
    for i, l in incorrect_images:
        normalized_images.append(i*STD + MEAN)
    normalized_images = np.array(normalized_images)
    t = torch.from_numpy(normalized_images)
    show_internal(torchvision.utils.make_grid(t, 10))
    

def show_with_gradcam(incorrect_images, m, use_cuda, STD, MEAN):
    images = []
    labels = []
    for i, l in incorrect_images:
        images.append(i)
        labels.append(l)
    incorrect_images_tensor = torch.from_numpy(np.array(images))
    label_tensor = torch.from_numpy(np.array(labels))

    ## pass to gradcam. For some reason the final block after GAP doesnt work! (convblock6)
    gradcam_output = compute_gradcam_image(incorrect_images_tensor,
                                           label_tensor,
                                           m, 
                                           [m.convblock5], 
                                           use_cuda, 
                                           STD, 
                                           MEAN)
    gradcam_output = np.array(gradcam_output)
    # gradcam_output = np.swapaxes(gradcam_output, 1, 3)
    t = torch.from_numpy(gradcam_output)
    show_internal(torchvision.utils.make_grid(t, 10))